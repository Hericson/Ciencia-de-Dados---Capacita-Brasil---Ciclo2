{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "442a9498",
      "metadata": {
        "id": "442a9498"
      },
      "source": [
        "![aula18_capa.png](./figuras/aula18_capa.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "ba151d70",
      "metadata": {
        "id": "ba151d70"
      },
      "outputs": [],
      "source": [
        "# !pip install nltk\n",
        "# !pip install gensim"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe2e299f",
      "metadata": {
        "id": "fe2e299f"
      },
      "source": [
        "## Modelos de Representação de Palavras\n",
        "\n",
        "### 1. Word2Vec\n",
        "- **Definição**: Algoritmo que representa palavras como vetores em um espaço contínuo.\n",
        "- **Estratégias**:\n",
        "  - CBOW (Continuous Bag of Words): Prediz a palavra com base no contexto.\n",
        "  - Skip-gram: Prediz o contexto com base na palavra central.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b95c848",
      "metadata": {
        "id": "1b95c848"
      },
      "source": [
        "**Frase de Exemplo**\n",
        "\n",
        "Frase: ```O gato gosta de peixe```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43ab3ce0",
      "metadata": {
        "id": "43ab3ce0"
      },
      "source": [
        "![aula18_cbow_skip.png](./figuras/aula18_cbow_skip.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3126e0b8",
      "metadata": {
        "id": "3126e0b8"
      },
      "source": [
        "- CBOW: Mais eficiente em dados pequenos. Foca no contexto para prever a palavra central.\n",
        "\n",
        "- Skip-Gram: Funciona melhor em grandes conjuntos de dados. Captura relações semânticas mais complexas ao prever o contexto usando a palavra central."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "19f74dec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19f74dec",
        "outputId": "204de849-6d4f-4524-c9d5-7f1c5a73af53",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vetor da palavra 'gato': [ 0.005486   -0.016719    0.01571279  0.0170703  -0.01917363  0.00489247\n",
            "  0.01981355 -0.01533167 -0.01393766 -0.01547715  0.01679156 -0.00136368\n",
            "  0.01828782 -0.01632169  0.00748585  0.0052674   0.00148326  0.00465364\n",
            " -0.01494053 -0.01871921  0.00470619  0.01229782  0.01597603  0.01147583\n",
            " -0.00155757  0.01661253 -0.01867324  0.00680927  0.00053412  0.00771772\n",
            "  0.01477519 -0.01345498  0.01116832 -0.0190494  -0.00160906 -0.01737562\n",
            " -0.01019605  0.01858218 -0.00371495  0.00582818  0.01814796  0.01787519\n",
            " -0.01642123 -0.00602607  0.01977482  0.01020862 -0.00317671 -0.01738286\n",
            "  0.00592334 -0.01335371]\n"
          ]
        }
      ],
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Exemplo de treinamento com Word2Vec\n",
        "sentences = [[\"gato\", \"adora\", \"peixe\"], [\"cachorro\", \"late\", \"para\", \"gatinho\"],  [\"rei\", \"governa\", \"reino\"],\n",
        "    [\"mulher\", \"vive\", \"no\", \"reino\"],\n",
        "    [\"homem\", \"ajuda\", \"no\", \"governo\"]]\n",
        "\n",
        "# Modelo CBOW (sg=0)\n",
        "model = Word2Vec(sentences, vector_size=50, window=3, min_count=1, sg=0, workers=4)\n",
        "\n",
        "# Modelo Skip-Gram (sg=1)\n",
        "#model = Word2Vec(sentences, vector_size=50, window=3, min_count=1,sg=1, workers=4)\n",
        "\n",
        "# Acessar vetor de uma palavra\n",
        "vector = model.wv[\"late\"]\n",
        "print(\"Vetor da palavra 'gato':\", vector)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc6d510d",
      "metadata": {
        "id": "dc6d510d"
      },
      "source": [
        "1.1 Treinamento com Parâmetros Personalizados\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "178fc52d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "178fc52d",
        "outputId": "0860da31-5b6e-46da-dada-17c70b1d21e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vetor da palavra 'gato': [-0.00066461 -0.00012106  0.01007604  0.01772279 -0.02013941 -0.01504357\n",
            "  0.01445466  0.01845654 -0.01282796 -0.00928387  0.01625643 -0.0037476\n",
            " -0.00769118  0.01316633 -0.00972467 -0.00321594  0.00959073  0.00473818\n",
            " -0.01993998 -0.02050222  0.01448102  0.01044507  0.01710199  0.0029958\n",
            "  0.01260991 -0.00619475 -0.00097859  0.01376643 -0.0161076  -0.00798778\n",
            " -0.01502496 -0.00327962  0.01809991 -0.01688035 -0.00644165 -0.004882\n",
            "  0.01832774 -0.01367588 -0.00164272 -0.01047571 -0.01772742  0.00929226\n",
            " -0.01705362 -0.01042047  0.00356706  0.00087586 -0.01482099  0.01721099\n",
            "  0.00981849  0.01833477]\n"
          ]
        }
      ],
      "source": [
        "# Construir o vocabulário\n",
        "model.build_vocab(sentences)\n",
        "\n",
        "# Treinar o modelo\n",
        "model.train(sentences, total_examples=model.corpus_count, epochs=1000)\n",
        "\n",
        "# Acessar vetor de uma palavra\n",
        "vector = model.wv[\"gato\"]\n",
        "print(\"Vetor da palavra 'gato':\", vector)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "600f5266",
      "metadata": {
        "id": "600f5266"
      },
      "source": [
        "1.2. Busca de Palavras Semelhantes\n",
        "Utilizar a função most_similar() para encontrar palavras com significado similar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "dacd360c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dacd360c",
        "outputId": "d20cee2b-7d17-4528-d887-2afb83aa8434"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Palavras semelhantes a 'gato': [('ajuda', 0.30082690715789795), ('vive', 0.2511043846607208), ('homem', 0.24055106937885284), ('reino', 0.20823067426681519), ('peixe', 0.1972850263118744)]\n"
          ]
        }
      ],
      "source": [
        "similar_words = model.wv.most_similar(\"gato\", topn=5)\n",
        "print(\"Palavras semelhantes a 'gato':\", similar_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54224c72",
      "metadata": {
        "id": "54224c72"
      },
      "source": [
        "1.3. Operações Aritméticas no Espaço de Palavras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "3acb8e3e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3acb8e3e",
        "outputId": "ebc5439c-6cdc-4340-8f4e-3bae813bb790"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resultado da analogia (Rei - Homem + Mulher): [('governa', 0.37330472469329834)]\n"
          ]
        }
      ],
      "source": [
        "# Exemplo de analogia: Rei - Homem + Mulher = ?\n",
        "analogia = model.wv.most_similar(positive=[\"rei\", \"mulher\"], negative=[\"homem\"], topn=1)\n",
        "print(\"Resultado da analogia (Rei - Homem + Mulher):\", analogia)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea968f0c",
      "metadata": {
        "id": "ea968f0c"
      },
      "source": [
        "1.4. Salvando e Carregando Modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "b4671035",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4671035",
        "outputId": "30e8d1a1-45b4-41f3-8c19-44d22ec74eda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vetor da palavra 'gato' no modelo carregado: [-0.00066461 -0.00012106  0.01007604  0.01772279 -0.02013941 -0.01504357\n",
            "  0.01445466  0.01845654 -0.01282796 -0.00928387  0.01625643 -0.0037476\n",
            " -0.00769118  0.01316633 -0.00972467 -0.00321594  0.00959073  0.00473818\n",
            " -0.01993998 -0.02050222  0.01448102  0.01044507  0.01710199  0.0029958\n",
            "  0.01260991 -0.00619475 -0.00097859  0.01376643 -0.0161076  -0.00798778\n",
            " -0.01502496 -0.00327962  0.01809991 -0.01688035 -0.00644165 -0.004882\n",
            "  0.01832774 -0.01367588 -0.00164272 -0.01047571 -0.01772742  0.00929226\n",
            " -0.01705362 -0.01042047  0.00356706  0.00087586 -0.01482099  0.01721099\n",
            "  0.00981849  0.01833477]\n"
          ]
        }
      ],
      "source": [
        "# Salvar o modelo\n",
        "model.save(\"word2vec.model\")\n",
        "\n",
        "# Carregar o modelo\n",
        "loaded_model = Word2Vec.load(\"word2vec.model\")\n",
        "print(\"Vetor da palavra 'gato' no modelo carregado:\", loaded_model.wv[\"gato\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "620d9fa3",
      "metadata": {
        "id": "620d9fa3"
      },
      "source": [
        "1.5. O Vocabulário do Modelo\n",
        "\n",
        "Explorar o vocabulário gerado e estatísticas do modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "692ba064",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "692ba064",
        "outputId": "7e21ee87-1037-4b6d-c31a-eaf347ce72df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tamanho do vocabulário: 16\n",
            "Palavras no vocabulário: ['no', 'reino', 'ajuda', 'governo', 'homem', 'vive', 'mulher', 'governa', 'rei', 'gatinho']\n"
          ]
        }
      ],
      "source": [
        "# Lista de palavras no vocabulário\n",
        "vocab = list(model.wv.key_to_index.keys())\n",
        "print(\"Tamanho do vocabulário:\", len(vocab))\n",
        "print(\"Palavras no vocabulário:\", vocab[:10])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04a9820f",
      "metadata": {},
      "source": [
        "blz, beleza, belez, bleza (independentes)\n",
        "(agrupar em uma única palavra): 'beleza'\n",
        "\n",
        "'beleza': {'blz', 'beleza', 'belez', 'bleza'}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf665171",
      "metadata": {
        "id": "cf665171"
      },
      "source": [
        "1.6. Similaridade entre Palavras\n",
        "\n",
        "Medir a similaridade semântica entre duas palavras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "10f7e588",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10f7e588",
        "outputId": "8ebc061e-7759-4895-d865-d1d4b73e0e27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Similaridade entre 'gato' e 'cachorro': 0.12971388\n",
            "Similaridade entre 'gato' e 'gatinho': 0.07045418\n"
          ]
        }
      ],
      "source": [
        "similarity = model.wv.similarity(\"rei\", \"reino\")\n",
        "print(\"Similaridade entre 'gato' e 'cachorro':\", similarity)\n",
        "\n",
        "similarity = model.wv.similarity(\"gato\", \"gatinho\")\n",
        "print(\"Similaridade entre 'gato' e 'gatinho':\", similarity)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2a9d389",
      "metadata": {
        "id": "d2a9d389"
      },
      "source": [
        "1.7. Análise de Outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "711a8649",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "711a8649",
        "outputId": "c5f10f46-ba72-45b6-babe-c7d11541c9a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Palavra fora do contexto: cachorro\n"
          ]
        }
      ],
      "source": [
        "outlier = model.wv.doesnt_match([\"gato\", \"cachorro\", \"peixe\", \"banana\"])\n",
        "print(\"Palavra fora do contexto:\", outlier)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc71d8ec",
      "metadata": {
        "id": "cc71d8ec"
      },
      "source": [
        "1.8. Preprocessamento de Dados\n",
        "\n",
        "Incluir a etapa de preprocessamento das sentenças antes do treinamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "929f2db7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "929f2db7",
        "outputId": "216256bf-24f8-40a0-b9db-1a1d903f83aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentenças processadas: [['gato', 'adora', 'peixe', 'fresco'], ['cachorros', 'animais', 'leais'], ['aluna', 'tirou', 'boa', 'nota']]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /home/hericson/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /home/hericson/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to\n",
            "[nltk_data]     /home/hericson/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "\n",
        "# Baixar stopwords e tokenizer do NLTK\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# Lista de stopwords em português\n",
        "stop_words = set(stopwords.words(\"portuguese\"))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Transformar em minúsculas\n",
        "    text = text.lower()\n",
        "    # Remover caracteres especiais e números\n",
        "    text = re.sub(r\"[^a-záéíóúãõâêîôûç\\s]\", \"\", text)\n",
        "    # Tokenizar o texto\n",
        "    tokens = word_tokenize(text)\n",
        "    # Remover stopwords\n",
        "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "    return filtered_tokens\n",
        "\n",
        "# Exemplo de uso\n",
        "sentences = [\"O gato adora peixe fresco!\", \"Cachorros são animais muito leais.\", \"A aluna tirou boa nota\"]\n",
        "processed_sentences = [preprocess_text(sentence) for sentence in sentences]\n",
        "print(\"Sentenças processadas:\", processed_sentences)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7aef4ab",
      "metadata": {
        "id": "b7aef4ab"
      },
      "source": [
        "1.9. Transfer Learning com Word2Vec\n",
        "\n",
        "Usar modelos pré-treinados para expandir a análise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "cdc43014",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "cdc43014",
        "outputId": "c507b5c2-9f5a-4c24-b990-c0920003f79b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vetor da palavra 'hombre': [-0.11572266 -0.11523438  0.18359375  0.38671875 -0.03710938  0.18847656\n",
            " -0.328125    0.1484375   0.02233887  0.09375     0.18066406 -0.40039062\n",
            " -0.23730469 -0.07373047  0.08740234  0.36132812  0.10644531  0.53125\n",
            "  0.29882812 -0.12988281 -0.08984375  0.11865234  0.22558594  0.07421875\n",
            " -0.00946045 -0.359375   -0.44921875 -0.21972656 -0.01434326 -0.00227356\n",
            "  0.30664062  0.31054688  0.18457031  0.19042969 -0.03491211  0.37304688\n",
            "  0.12890625  0.09814453  0.16210938 -0.06347656  0.07470703 -0.30859375\n",
            "  0.421875    0.20703125  0.06738281 -0.04541016 -0.10986328 -0.01269531\n",
            " -0.125       0.2890625  -0.26757812  0.19921875  0.15429688 -0.13671875\n",
            "  0.08447266  0.19042969 -0.00280762  0.07275391  0.07763672  0.14941406\n",
            " -0.0546875   0.125      -0.19628906 -0.012146   -0.14550781 -0.04541016\n",
            " -0.08886719 -0.27148438  0.12695312  0.09472656  0.359375    0.33007812\n",
            " -0.25        0.11914062 -0.07080078  0.19628906  0.11230469  0.23730469\n",
            " -0.30664062 -0.15234375  0.10351562  0.13476562 -0.359375   -0.58984375\n",
            " -0.03149414  0.3125     -0.14648438  0.41210938  0.3828125  -0.00361633\n",
            " -0.15917969  0.05444336 -0.01745605  0.25390625  0.01263428 -0.02062988\n",
            "  0.12695312  0.22460938  0.13183594 -0.36132812 -0.41015625 -0.05883789\n",
            "  0.12988281 -0.07763672  0.00854492 -0.25585938  0.18652344  0.19042969\n",
            " -0.18261719  0.234375    0.06445312 -0.16894531  0.00897217 -0.03710938\n",
            "  0.00616455  0.13183594 -0.01940918  0.06835938  0.125      -0.12597656\n",
            "  0.06445312 -0.09472656 -0.25       -0.18847656  0.25976562 -0.04077148\n",
            " -0.11621094 -0.05053711  0.09472656 -0.12402344 -0.5        -0.2890625\n",
            " -0.00346375  0.10791016 -0.07177734 -0.00279236 -0.29101562  0.13085938\n",
            "  0.27734375  0.10839844  0.16796875 -0.15332031  0.03125    -0.12109375\n",
            "  0.07324219  0.13964844 -0.12109375  0.07226562  0.16894531 -0.00219727\n",
            "  0.34765625 -0.35546875 -0.2578125  -0.02258301 -0.38671875  0.12402344\n",
            " -0.09912109  0.23339844 -0.0402832  -0.24121094  0.06445312  0.06445312\n",
            "  0.4453125   0.06347656 -0.33398438 -0.20703125  0.29296875  0.14648438\n",
            " -0.203125    0.22070312  0.02294922 -0.19335938  0.26757812 -0.14453125\n",
            " -0.11328125  0.21289062 -0.12304688 -0.04541016  0.21386719 -0.04345703\n",
            " -0.13476562 -0.22949219  0.07373047  0.04296875 -0.30078125 -0.05126953\n",
            " -0.04052734 -0.16308594 -0.1484375   0.10791016  0.15625     0.13183594\n",
            " -0.07714844  0.14453125  0.24707031  0.07080078 -0.2890625   0.22460938\n",
            " -0.25390625  0.22265625 -0.17578125  0.02172852 -0.05688477  0.02758789\n",
            "  0.08105469 -0.08300781  0.01080322 -0.10839844 -0.25195312  0.05883789\n",
            " -0.16601562  0.04077148 -0.06982422 -0.140625   -0.36914062  0.31054688\n",
            " -0.28320312 -0.16308594 -0.47265625  0.25390625 -0.14453125  0.13378906\n",
            "  0.00476074  0.18945312  0.38671875  0.11816406  0.28320312  0.01794434\n",
            "  0.05175781  0.13769531 -0.00570679 -0.29296875 -0.10693359  0.16113281\n",
            "  0.22558594  0.09277344  0.10839844 -0.07275391  0.06835938 -0.06982422\n",
            "  0.28320312  0.14941406 -0.00130463  0.11962891  0.04907227 -0.19335938\n",
            " -0.203125    0.21191406 -0.03540039  0.16503906 -0.05029297  0.21386719\n",
            "  0.04956055  0.34765625  0.28320312  0.02490234 -0.05981445 -0.36132812\n",
            " -0.10644531 -0.17675781  0.19921875  0.01092529  0.3359375  -0.09863281\n",
            "  0.1796875   0.04101562 -0.04882812 -0.04589844 -0.33984375  0.08398438\n",
            " -0.234375    0.1640625   0.05297852 -0.08251953 -0.04296875  0.125\n",
            " -0.05834961  0.02502441 -0.23632812  0.39648438  0.09960938 -0.0390625\n",
            "  0.08935547 -0.17285156  0.00164795 -0.33398438 -0.34960938 -0.04931641\n",
            " -0.13964844 -0.00111389  0.16503906  0.17382812 -0.0291748  -0.02246094\n",
            "  0.19726562  0.20996094  0.05761719 -0.09570312  0.00741577  0.31445312]\n"
          ]
        }
      ],
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "# Carregar um modelo pré-treinado (como o Word2Vec do Google News)\n",
        "# baixar em https://drive.usercontent.google.com/download?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM&export=download&authuser=0\n",
        "\n",
        "pretrained_model = KeyedVectors.load_word2vec_format(\"datasets/GoogleNews-vectors-negative300.bin.gz\", binary=True)\n",
        "print(\"Vetor da palavra 'hombre':\", pretrained_model[\"hombre\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "id": "8353d1d5",
      "metadata": {
        "id": "8353d1d5",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Palavras semelhantes a 'hombre': [('strawberries', 0.7941855192184448), ('blueberry', 0.7661275863647461), ('berry', 0.7010524272918701), ('tomato', 0.6888598203659058), ('peaches', 0.6870250701904297)]\n"
          ]
        }
      ],
      "source": [
        "similar_words2 = pretrained_model.most_similar(\"strawberry\", topn=5)\n",
        "print(\"Palavras semelhantes a 'hombre':\", similar_words2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abd2e2fb",
      "metadata": {
        "id": "abd2e2fb"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5647af6",
      "metadata": {
        "id": "e5647af6"
      },
      "source": [
        "### 2.GloVe"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd24312c",
      "metadata": {
        "id": "dd24312c"
      },
      "source": [
        "O **GloVe (Global Vectors for Word Representation)** é um modelo de aprendizado que gera representações vetoriais para palavras com base em uma matriz de coocorrência de palavras em um grande corpus de texto.\n",
        "\n",
        "Entendendo a Coocorrência:\n",
        "\n",
        "Frase:\n",
        "\n",
        "```O gato gosta de peixe```\n",
        "\n",
        "![aula18_coocorr%C3%AAncia.png](./figuras/aula18_coocorr%C3%AAncia.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b9edcfb",
      "metadata": {
        "id": "6b9edcfb"
      },
      "source": [
        "O GloVe utiliza essa matriz de coocorrência para aprender vetores densos para cada palavra. Ele tenta ajustar os vetores para que as relações semânticas sejam capturadas, como:\n",
        "\n",
        "Vetor(\"gato\") deve estar mais próximo de Vetor(\"peixe\") do que de Vetor(\"carro\").\n",
        "\n",
        "Vetores podem ser combinados para capturar analogias, como:\n",
        "\n",
        "- Vetor(\"rei\") −> Vetor(\"homem\") + Vetor(\"mulher\") ≈ Vetor(\"rainha\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8270360e",
      "metadata": {
        "id": "8270360e"
      },
      "source": [
        "### 2.1. Baixar e Carregar o Modelo GloVe\n",
        "\n",
        "Vamos baixar um modelo GloVe pré-treinado e o convertendo para um formato compatível com a biblioteca `gensim`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "282ffd01",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "282ffd01",
        "outputId": "89bc1751-36ac-450c-93f5-a7713682e934"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_9782/2686739773.py:9: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
            "  glove2word2vec(glove_file, word2vec_output_file)\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'datasets/glove.6B (2)/glove.6B.100d.txt'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[15], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m glove_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasets/glove.6B (2)/glove.6B.100d.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m word2vec_output_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasets/glove.6B.100d.word2vec.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 9\u001b[0m \u001b[43mglove2word2vec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mglove_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword2vec_output_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Carregar o modelo\u001b[39;00m\n\u001b[1;32m     12\u001b[0m model \u001b[38;5;241m=\u001b[39m KeyedVectors\u001b[38;5;241m.\u001b[39mload_word2vec_format(word2vec_output_file, binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
            "File \u001b[0;32m~/anaconda3/envs/my_projects/lib/python3.9/site-packages/gensim/utils.py:1521\u001b[0m, in \u001b[0;36mdeprecated.<locals>.decorator.<locals>.new_func1\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1514\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_func1\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1516\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1517\u001b[0m         fmt\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, reason\u001b[38;5;241m=\u001b[39mreason),\n\u001b[1;32m   1518\u001b[0m         category\u001b[38;5;241m=\u001b[39m\u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[1;32m   1519\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m   1520\u001b[0m     )\n\u001b[0;32m-> 1521\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/my_projects/lib/python3.9/site-packages/gensim/scripts/glove2word2vec.py:109\u001b[0m, in \u001b[0;36mglove2word2vec\u001b[0;34m(glove_input_file, word2vec_output_file)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;129m@deprecated\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mglove2word2vec\u001b[39m(glove_input_file, word2vec_output_file):\n\u001b[1;32m     94\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert `glove_input_file` in GloVe format to word2vec format and write it to `word2vec_output_file`.\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m \n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m     glovekv \u001b[38;5;241m=\u001b[39m \u001b[43mKeyedVectors\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_word2vec_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mglove_input_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mno_header\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m     num_lines, num_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(glovekv), glovekv\u001b[38;5;241m.\u001b[39mvector_size\n\u001b[1;32m    112\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconverting \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m vectors from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, num_lines, glove_input_file, word2vec_output_file)\n",
            "File \u001b[0;32m~/anaconda3/envs/my_projects/lib/python3.9/site-packages/gensim/models/keyedvectors.py:1719\u001b[0m, in \u001b[0;36mKeyedVectors.load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001b[0m\n\u001b[1;32m   1672\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   1673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_word2vec_format\u001b[39m(\n\u001b[1;32m   1674\u001b[0m         \u001b[38;5;28mcls\u001b[39m, fname, fvocab\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m'\u001b[39m, unicode_errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1675\u001b[0m         limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, datatype\u001b[38;5;241m=\u001b[39mREAL, no_header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1676\u001b[0m     ):\n\u001b[1;32m   1677\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load KeyedVectors from a file produced by the original C word2vec-tool format.\u001b[39;00m\n\u001b[1;32m   1678\u001b[0m \n\u001b[1;32m   1679\u001b[0m \u001b[38;5;124;03m    Warnings\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1717\u001b[0m \n\u001b[1;32m   1718\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1719\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_word2vec_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1720\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbinary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43municode_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43municode_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1721\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatatype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatatype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mno_header\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mno_header\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1722\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/my_projects/lib/python3.9/site-packages/gensim/models/keyedvectors.py:2048\u001b[0m, in \u001b[0;36m_load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001b[0m\n\u001b[1;32m   2045\u001b[0m             counts[word] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(count)\n\u001b[1;32m   2047\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloading projection weights from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, fname)\n\u001b[0;32m-> 2048\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fin:\n\u001b[1;32m   2049\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m no_header:\n\u001b[1;32m   2050\u001b[0m         \u001b[38;5;66;03m# deduce both vocab_size & vector_size from 1st pass over file\u001b[39;00m\n\u001b[1;32m   2051\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m binary:\n",
            "File \u001b[0;32m~/anaconda3/envs/my_projects/lib/python3.9/site-packages/smart_open/smart_open_lib.py:177\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, compression, transport_params)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transport_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    175\u001b[0m     transport_params \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 177\u001b[0m fobj \u001b[38;5;241m=\u001b[39m \u001b[43m_shortcut_open\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuffering\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuffering\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnewline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fobj\n",
            "File \u001b[0;32m~/anaconda3/envs/my_projects/lib/python3.9/site-packages/smart_open/smart_open_lib.py:375\u001b[0m, in \u001b[0;36m_shortcut_open\u001b[0;34m(uri, mode, compression, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m    373\u001b[0m     open_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merrors\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m errors\n\u001b[0;32m--> 375\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_builtin_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffering\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuffering\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mopen_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'datasets/glove.6B (2)/glove.6B.100d.txt'"
          ]
        }
      ],
      "source": [
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "# Converter o formato GloVe para Word2Vec\n",
        "# baixar em : http://nlp.stanford.edu/data/glove.6B.zip\n",
        "glove_url = \"http://nlp.stanford.edu/data/glove.6B.zip\"\n",
        "glove_file = \"datasets/glove.6B (2)/glove.6B.100d.txt\"\n",
        "word2vec_output_file = \"datasets/glove.6B.100d.word2vec.txt\"\n",
        "glove2word2vec(glove_file, word2vec_output_file)\n",
        "\n",
        "# Carregar o modelo\n",
        "model = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b175b993",
      "metadata": {
        "id": "b175b993"
      },
      "source": [
        "### 2.1 Encontrar Palavras Semelhantes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "id": "a0e07255",
      "metadata": {
        "id": "a0e07255"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Palavras semelhantes a 'king': [('boyfriend', 0.9419270157814026), ('fiancee', 0.8946628570556641), ('fiance', 0.8751725554466248)]\n"
          ]
        }
      ],
      "source": [
        "# Encontrar palavras semelhantes\n",
        "similar_words = model.most_similar(\"girlfriend\", topn=3)\n",
        "print(\"Palavras semelhantes a 'king':\", similar_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9792712",
      "metadata": {
        "id": "f9792712"
      },
      "source": [
        "### 2.2 Calcular Similaridade entre Palavras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "id": "130186fa",
      "metadata": {
        "id": "130186fa",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Similaridade entre 'woman' e 'man': 0.6746013\n"
          ]
        }
      ],
      "source": [
        "# Similaridade entre palavras\n",
        "similarity = model.similarity(\"big\", \"large\")\n",
        "print(\"Similaridade entre 'woman' e 'man':\", similarity)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e45d09ce",
      "metadata": {
        "id": "e45d09ce"
      },
      "source": [
        "### 2.3 Operações de Vetores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "id": "0e78f4c4",
      "metadata": {
        "id": "0e78f4c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resultado da analogia (King - Man + Woman): [('horses', 0.6599798202514648)]\n"
          ]
        }
      ],
      "source": [
        "analogia = model.most_similar(positive=[\"horse\", \"farm\"], negative=[\"fruit\"], topn=1)\n",
        "print(\"Resultado da analogia (King - Man + Woman):\", analogia)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "id": "727259b6",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('flowers', 0.8246087431907654),\n",
              " ('red', 0.8242772221565247),\n",
              " ('tree', 0.8163017630577087),\n",
              " ('yellow', 0.8078889846801758),\n",
              " ('purple', 0.7923315167427063),\n",
              " ('blue', 0.7852816581726074),\n",
              " ('pink', 0.782580554485321),\n",
              " ('white', 0.7795533537864685),\n",
              " ('wood', 0.7765533328056335),\n",
              " ('bright', 0.7696632742881775)]"
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "analogia = model.most_similar(positive=[\"flower\", \"green\"])\n",
        "analogia"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72e2f8a7",
      "metadata": {
        "id": "72e2f8a7"
      },
      "source": [
        "### 2.4 Palavras Fora do Contexto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "id": "0a529f02",
      "metadata": {
        "id": "0a529f02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Palavra fora do contexto: small\n"
          ]
        }
      ],
      "source": [
        "# Identificar palavra fora do contexto\n",
        "outlier = model.doesnt_match([\"blue\", \"green\", \"yellow\", \"small\"])\n",
        "print(\"Palavra fora do contexto:\", outlier)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e5df926",
      "metadata": {
        "id": "7e5df926"
      },
      "source": [
        "### 2.5 Função para Representar Sentenças como Vetores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "ad082a6a",
      "metadata": {
        "id": "ad082a6a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def sentence_to_vector(sentence, model):\n",
        "    words = sentence.lower().split()\n",
        "    vectors = [model[word] for word in words if word in model]\n",
        "    if vectors:\n",
        "        return np.mean(vectors, axis=0)\n",
        "    else:\n",
        "        return np.zeros(model.vector_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40d73031",
      "metadata": {
        "id": "40d73031"
      },
      "source": [
        "### 2.6 Comparação de Sentenças"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "6087f501",
      "metadata": {
        "id": "6087f501"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "argument of type 'Word2Vec' is not iterable",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[14], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m sentence2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe queen is powerful\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Calcular os vetores\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m vector1 \u001b[38;5;241m=\u001b[39m \u001b[43msentence_to_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m vector2 \u001b[38;5;241m=\u001b[39m sentence_to_vector(sentence2, model)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Similaridade entre sentenças\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[13], line 5\u001b[0m, in \u001b[0;36msentence_to_vector\u001b[0;34m(sentence, model)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msentence_to_vector\u001b[39m(sentence, model):\n\u001b[1;32m      4\u001b[0m     words \u001b[38;5;241m=\u001b[39m sentence\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39msplit()\n\u001b[0;32m----> 5\u001b[0m     vectors \u001b[38;5;241m=\u001b[39m [model[word] \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m model]\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m vectors:\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(vectors, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
            "Cell \u001b[0;32mIn[13], line 5\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msentence_to_vector\u001b[39m(sentence, model):\n\u001b[1;32m      4\u001b[0m     words \u001b[38;5;241m=\u001b[39m sentence\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39msplit()\n\u001b[0;32m----> 5\u001b[0m     vectors \u001b[38;5;241m=\u001b[39m [model[word] \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mword\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m]\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m vectors:\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(vectors, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
            "\u001b[0;31mTypeError\u001b[0m: argument of type 'Word2Vec' is not iterable"
          ]
        }
      ],
      "source": [
        "# Sentenças de exemplo\n",
        "sentence1 = \"The king is strong\"\n",
        "sentence2 = \"The queen is powerful\"\n",
        "\n",
        "# Calcular os vetores\n",
        "vector1 = sentence_to_vector(sentence1, model)\n",
        "vector2 = sentence_to_vector(sentence2, model)\n",
        "\n",
        "# Similaridade entre sentenças\n",
        "from numpy.linalg import norm\n",
        "similarity = np.dot(vector1, vector2) / (norm(vector1) * norm(vector2))\n",
        "print(f\"Similaridade entre as sentenças: {similarity:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18de7551",
      "metadata": {
        "id": "18de7551"
      },
      "source": [
        "**Obs: experimente usar outros modelos GloVe (100, 200 ou 300 dimensões) para verificar como a dimensionalidade impacta os resultados!**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fa3e67c",
      "metadata": {
        "id": "5fa3e67c"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c9dd271",
      "metadata": {
        "id": "8c9dd271"
      },
      "source": [
        "### 3.  Aplicação prática de Redes Neurais Recorrentes (RNN) com Long Short-Term Memory (LSTM) para análise de sentimentos"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3e9cae6",
      "metadata": {
        "id": "d3e9cae6"
      },
      "source": [
        "### 3.1 Importando as bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "726d8566",
      "metadata": {
        "id": "726d8566"
      },
      "outputs": [],
      "source": [
        "#pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "25af34b0",
      "metadata": {
        "id": "25af34b0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-03 14:45:49.043047: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-07-03 14:45:49.243129: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1751564749.315210    9782 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1751564749.351503    9782 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1751564749.523391    9782 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1751564749.523417    9782 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1751564749.523419    9782 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1751564749.523420    9782 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-07-03 14:45:49.541110: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /home/hericson/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, SimpleRNN\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "import os\n",
        "import tarfile\n",
        "import re\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "# Baixar stopwords\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a56bdd1c",
      "metadata": {
        "id": "a56bdd1c"
      },
      "source": [
        "### 3.2 Preparando o dataset\n",
        "\n",
        "https://ai.stanford.edu/~amaas/data/sentiment/\n",
        "\n",
        "Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christopher Potts. (2011). Learning Word Vectors for Sentiment Analysis. The 49th Annual Meeting of the Association for Computational Linguistics (ACL 2011)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "126e1c61",
      "metadata": {
        "id": "126e1c61"
      },
      "source": [
        "Este é um conjunto de dados para classificação binária de sentimentos, contendo substancialmente mais dados do que conjuntos de dados de referência anteriores. Fornecemos um conjunto de 25.000 resenhas de filmes altamente polarizadas para treinamento e 25.000 para teste. Há também dados adicionais não rotulados disponíveis para uso. São fornecidos os formatos de texto bruto e de \"bag of words\" já processados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "770a6329",
      "metadata": {
        "id": "770a6329",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Caminhos para os dados\n",
        "# Baixar em: https://ai.stanford.edu/~amaas/data/sentiment/\n",
        "train_pos_dir = \"datasets/aclImdb_v1/aclImdb/train/pos\"\n",
        "train_neg_dir = \"datasets/aclImdb_v1/aclImdb/train/neg\"\n",
        "\n",
        "# Função para carregar textos e rótulos\n",
        "def load_imdb_data(pos_dir, neg_dir):\n",
        "    texts, labels = [], []\n",
        "    for file in os.listdir(pos_dir):\n",
        "        with open(os.path.join(pos_dir, file), encoding=\"utf-8\") as f:\n",
        "            texts.append(f.read())\n",
        "            labels.append(1)  # 1 para avaliações positivas\n",
        "    for file in os.listdir(neg_dir):\n",
        "        with open(os.path.join(neg_dir, file), encoding=\"utf-8\") as f:\n",
        "            texts.append(f.read())\n",
        "            labels.append(0)  # 0 para avaliações negativas\n",
        "    return texts, labels\n",
        "\n",
        "# Carregar os dados\n",
        "texts, labels = load_imdb_data(train_pos_dir, train_neg_dir)\n",
        "# print(texts[0])\n",
        "# print(labels[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "948e07db",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('I saw this at the premiere in Melbourne<br /><br />It is shallow, two-dimensional, unaffecting and, hard to believe given the subject matter, boring. The actors are passable, but they didn\\'t have much to work with given the very plodding and unimpressive script. For those who might have worried that Ned Kelly would be over-intellectualised, you can take comfort in the fact that this telling of the story is utterly without any literary depth at all, told entirely on the surface and full of central casting standards. However, it doesn\\'t work as a popcorn film either. Its pacing is too off-kilter and its craft is too lacking to satisfy even on the level of a mundane actioner.<br /><br />I very much doubt Gregor Jordan could sit back and say to himself \"this is the best I could have done with the material\".<br /><br />Ned Kelly is a fascinating figure, and equally so is the national response to him. Possibly folk genius, possibly class warrior, possibly psychopath and probably all these things, he has dominated Australian true mythology for over 120 years. Once again, his story has failed miserably on the big screen.<br /><br />Such is life.',\n",
              " 0)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "texts[100], labels[100]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d0d3d28",
      "metadata": {
        "id": "5d0d3d28"
      },
      "source": [
        "#### Dividindo os dados\n",
        "\n",
        "Dividimos os dados em conjuntos de treinamento e teste."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "2127d782",
      "metadata": {
        "id": "2127d782"
      },
      "outputs": [],
      "source": [
        "# Dividir em conjunto de treino e teste\n",
        "texts_train, texts_test, labels_train, labels_test = train_test_split(\n",
        "    texts, labels, test_size=0.3, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e9008ba",
      "metadata": {
        "id": "8e9008ba"
      },
      "source": [
        "### 3.3 Pré-processamento de Texto\n",
        "\n",
        "Remover stopwords, tokenizar e criar sequências de entrada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "ca5fc9c5",
      "metadata": {
        "id": "ca5fc9c5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /home/hericson/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "nltk.download(\"stopwords\")\n",
        "\n",
        "# Remover stopwords e limpar o texto\n",
        "stop_words = set(stopwords.words(\"english\"))  # Dataset IMDB está em inglês\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[^a-z\\s]\", \"\", text)  # Remover caracteres especiais\n",
        "    words = text.split()\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "    return \" \".join(words)\n",
        "\n",
        "# Pré-processar os textos\n",
        "texts_train = [preprocess_text(text) for text in texts_train]\n",
        "texts_test = [preprocess_text(text) for text in texts_test]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "a7ea4a82",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('reason tv guide gave two half stars plus faye dunaway definitely looked like something see oh may worst film ive ever seen ever horrid acting every time girl asks boy whats wrong shouted tv cant act asks needs yell need acting lessons unbelievably bad dialog give back organsbr br brian depalma wannabe ending beyond awful wanted like dunaway one best actors ever production values pretty goodbr br wowzers laughing laughing timebr br dont even bother curiosity first mistake staying definitely second third fourth',\n",
              " 0)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "texts_train[2], labels_train[2]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "007a2851",
      "metadata": {
        "id": "007a2851"
      },
      "source": [
        "### 3.4 Tokenização e Sequencialização"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "3e7c8c60",
      "metadata": {
        "id": "3e7c8c60"
      },
      "outputs": [],
      "source": [
        "# Tokenizar os textos\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(texts_train)\n",
        "\n",
        "# Converter os textos para sequências\n",
        "X_train = tokenizer.texts_to_sequences(texts_train)\n",
        "X_test = tokenizer.texts_to_sequences(texts_test)\n",
        "\n",
        "# # Padronizar os comprimentos das sequências\n",
        "max_len = 100  # Ajuste baseado no dataset\n",
        "X_train = pad_sequences(X_train, maxlen=max_len, padding=\"post\")\n",
        "X_test = pad_sequences(X_test, maxlen=max_len, padding=\"post\")\n",
        "\n",
        "# Converter rótulos para arrays NumPy\n",
        "y_train = np.array(labels_train)\n",
        "y_test = np.array(labels_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "70d28d0f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'four eyed monsters follows relationship shy reclusive videographer equally estranged struggling artist living big apple develop unlikely romance help internet dating site unusual method communication foregoing verbal take writing notes later communicating videobr br film based upon creators arin crumley susan buice relationship besides writing directing take acting lead characters well elements avantgarde antiplot docudrama film scatters wind undecided structure nestled neatly narcissism selfindulgencebr br movie wears brief separation deterioration intriguing form communication grow old couple face hardship reality focusing solely inner conflict woes relationship film struggles stagnant narrative neither original poignant could easily circumvented addition subplot external conflict third act none montage melodrama leads nowherebr br even aggravating films descent story reality abruptly concludes open ended unsatisfying finish would fine dandy question asked meaning discovered ponderedbr br side note film contains beautiful animation vivid moving soundtrack one interesting aspects productionbr br always watch film decide'"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "texts_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "dfe5cb4e",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2324,  510,  113, 1991, 2238,  980,  239, 2930, 3959, 2063, 2458,\n",
              "       4635,  101,  313, 3960,  273,    1,    3,  359,  629, 4636, 2873,\n",
              "        842, 1165,  313,  693,  101,   24,  362,   28,   25,  730,    3,\n",
              "       1791, 1881,    1,    2, 2503, 1253, 1921,  843, 2931,   74,  251,\n",
              "        297,  616, 3961, 3191, 3349, 1882,  842,    3, 2989, 1158,  711,\n",
              "         71,   19,  622, 1573, 2504, 1882,  768,  331,  339, 3528, 2700,\n",
              "        769,    1,    6,   30, 4810,   15,  616,  805,  872, 4637, 1108,\n",
              "          9,  520,  682, 1618, 1100, 2037,    1,  506,  775,    3, 1270,\n",
              "        389,  834,  990,  745,    4,  112, 1434,    1,  180,   31,    3,\n",
              "        861], dtype=int32)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ecd89941",
      "metadata": {},
      "source": [
        "### Predição em um novo review?\n",
        "\n",
        "rev = \"Que filme legal, gostei demais, ótimos atores\"\n",
        "\n",
        "#### Objetivo?\n",
        "\n",
        "Prever se o review é bom ou ruim\n",
        "\n",
        "# Qual a primeira etapa?\n",
        "\n",
        "1 - Pré-processar - remover stopwords, remover caracteres inválidos, números\n",
        "\n",
        "2 - Tokenizar (Separar as palavras relevantes em tokens)\n",
        "\n",
        "3 - Codificar o texto em formato numérico\n",
        "\n",
        "4 - Realizar Predições"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "373fc7a4",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[  2, 897,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0]], dtype=int32)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_reviews = [\"the movie was amazing!\"]\n",
        "new_reviews = [preprocess_text(review) for review in new_reviews]\n",
        "new_sequences = tokenizer.texts_to_sequences(new_reviews)\n",
        "new_X = pad_sequences(new_sequences, maxlen=max_len, padding=\"post\")\n",
        "new_X\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "e6beb8e2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(array([[0]], dtype=int32), array([[2.5484915e-05]], dtype=float32))"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = (modelRNN.predict(new_X) > 0.5).astype(\"int32\"), modelRNN.predict(new_X)  # Converte previsões para 0 ou 1\n",
        "y_pred\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec5700b0",
      "metadata": {
        "id": "ec5700b0"
      },
      "source": [
        "### 3.5 Construindo o Modelo com RNN e Treinando"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "65671589",
      "metadata": {
        "id": "65671589"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-03 14:52:38.153607: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.9880 - loss: 0.0472 - val_accuracy: 1.0000 - val_loss: 9.2666e-05\n",
            "Epoch 2/10\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9999 - loss: 8.5193e-04 - val_accuracy: 1.0000 - val_loss: 7.8668e-05\n",
            "Epoch 3/10\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9997 - loss: 0.0034 - val_accuracy: 1.0000 - val_loss: 3.9388e-05\n",
            "Epoch 4/10\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 2.8462e-04 - val_accuracy: 1.0000 - val_loss: 1.1834e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.9997 - loss: 0.0029 - val_accuracy: 1.0000 - val_loss: 2.7204e-05\n",
            "Epoch 6/10\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.9999 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 3.6213e-05\n",
            "Epoch 7/10\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.9998 - loss: 0.0017 - val_accuracy: 1.0000 - val_loss: 2.8506e-05\n",
            "Epoch 8/10\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 5.6327e-05 - val_accuracy: 1.0000 - val_loss: 1.1467e-05\n",
            "Epoch 9/10\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.9999 - loss: 5.6992e-04 - val_accuracy: 1.0000 - val_loss: 3.9052e-05\n",
            "Epoch 10/10\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9999 - loss: 0.0010 - val_accuracy: 1.0000 - val_loss: 3.1247e-05\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 3.1234e-05\n",
            "Loss: 0.0000, Accuracy: 1.0000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step\n",
            "Review: movie fantastic loved | Sentiment: Negative\n",
            "Review: hated film terrible | Sentiment: Negative\n"
          ]
        }
      ],
      "source": [
        "# Criar o modelo\n",
        "modelRNN = Sequential([\n",
        "    Embedding(input_dim=5000, output_dim=64),  # Camada de Embedding\n",
        "    SimpleRNN(128, return_sequences=False),  # Camada RNN\n",
        "    Dropout(0.5),  # Regularização\n",
        "    Dense(1, activation=\"sigmoid\")  # Camada de saída para classificação binária\n",
        "])\n",
        "\n",
        "# Compilar o modelo\n",
        "modelRNN.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "modelRNN.fit(X_train, y_train,epochs=10,batch_size=32,validation_data=(X_test, y_test),verbose=1)\n",
        "\n",
        "\n",
        "# Avaliar no conjunto de teste\n",
        "loss, accuracy = modelRNN.evaluate(X_test, y_test)\n",
        "print(f\"Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Fazer previsões em novas frases\n",
        "new_reviews = [\"The movie was fantastic! I loved it.\", \"I hated the film. It was terrible.\"]\n",
        "new_reviews = [preprocess_text(review) for review in new_reviews]\n",
        "new_sequences = tokenizer.texts_to_sequences(new_reviews)\n",
        "new_X = pad_sequences(new_sequences, maxlen=max_len, padding=\"post\")\n",
        "\n",
        "# Previsões\n",
        "predictions = modelRNN.predict(new_X)\n",
        "for review, pred in zip(new_reviews, predictions):\n",
        "    sentiment = \"Positive\" if pred > 0.5 else \"Negative\"\n",
        "    print(f\"Review: {review} | Sentiment: {sentiment}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "f0dc38b2",
      "metadata": {
        "id": "f0dc38b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/hericson/anaconda3/envs/my_projects/lib/python3.9/site-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "The number of FixedLocator locations (1), usually from a call to set_ticks, does not match the number of labels (2).",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[48], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Exibir a matriz de confusão\u001b[39;00m\n\u001b[1;32m      8\u001b[0m disp \u001b[38;5;241m=\u001b[39m ConfusionMatrixDisplay(confusion_matrix\u001b[38;5;241m=\u001b[39mcm, display_labels\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNegative\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPositive\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m----> 9\u001b[0m \u001b[43mdisp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatriz de Confusão\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
            "File \u001b[0;32m~/anaconda3/envs/my_projects/lib/python3.9/site-packages/sklearn/metrics/_plot/confusion_matrix.py:185\u001b[0m, in \u001b[0;36mConfusionMatrixDisplay.plot\u001b[0;34m(self, include_values, cmap, xticks_rotation, values_format, ax, colorbar, im_kw, text_kw)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m colorbar:\n\u001b[1;32m    184\u001b[0m     fig\u001b[38;5;241m.\u001b[39mcolorbar(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mim_, ax\u001b[38;5;241m=\u001b[39max)\n\u001b[0;32m--> 185\u001b[0m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxticks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_classes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43myticks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_classes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxticklabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisplay_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43myticklabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisplay_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mylabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTrue label\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPredicted label\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_ylim((n_classes \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m))\n\u001b[1;32m    195\u001b[0m plt\u001b[38;5;241m.\u001b[39msetp(ax\u001b[38;5;241m.\u001b[39mget_xticklabels(), rotation\u001b[38;5;241m=\u001b[39mxticks_rotation)\n",
            "File \u001b[0;32m~/anaconda3/envs/my_projects/lib/python3.9/site-packages/matplotlib/artist.py:147\u001b[0m, in \u001b[0;36mArtist.__init_subclass__.<locals>.<lambda>\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mset, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_autogenerated_signature\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;66;03m# Don't overwrite cls.set if the subclass or one of its parents\u001b[39;00m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;66;03m# has defined a set method set itself.\u001b[39;00m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;66;03m# If there was no explicit definition, cls.set is inherited from\u001b[39;00m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;66;03m# the hierarchy of auto-generated set methods, which hold the\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;66;03m# flag _autogenerated_signature.\u001b[39;00m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 147\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[43mArtist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mset\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mset\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "File \u001b[0;32m~/anaconda3/envs/my_projects/lib/python3.9/site-packages/matplotlib/artist.py:1231\u001b[0m, in \u001b[0;36mArtist.set\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1228\u001b[0m     \u001b[38;5;66;03m# docstring and signature are auto-generated via\u001b[39;00m\n\u001b[1;32m   1229\u001b[0m     \u001b[38;5;66;03m# Artist._update_set_signature_and_docstring() at the end of the\u001b[39;00m\n\u001b[1;32m   1230\u001b[0m     \u001b[38;5;66;03m# module.\u001b[39;00m\n\u001b[0;32m-> 1231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcbook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/my_projects/lib/python3.9/site-packages/matplotlib/artist.py:1223\u001b[0m, in \u001b[0;36mArtist._internal_update\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_internal_update\u001b[39m(\u001b[38;5;28mself\u001b[39m, kwargs):\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1218\u001b[0m \u001b[38;5;124;03m    Update artist properties without prenormalizing them, but generating\u001b[39;00m\n\u001b[1;32m   1219\u001b[0m \u001b[38;5;124;03m    errors as if calling `set`.\u001b[39;00m\n\u001b[1;32m   1220\u001b[0m \n\u001b[1;32m   1221\u001b[0m \u001b[38;5;124;03m    The lack of prenormalization is to maintain backcompatibility.\u001b[39;00m\n\u001b[1;32m   1222\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_props\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{cls.__name__}\u001b[39;49;00m\u001b[38;5;124;43m.set() got an unexpected keyword argument \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{prop_name!r}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/my_projects/lib/python3.9/site-packages/matplotlib/artist.py:1199\u001b[0m, in \u001b[0;36mArtist._update_props\u001b[0;34m(self, props, errfmt)\u001b[0m\n\u001b[1;32m   1196\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(func):\n\u001b[1;32m   1197\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1198\u001b[0m                     errfmt\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m), prop_name\u001b[38;5;241m=\u001b[39mk))\n\u001b[0;32m-> 1199\u001b[0m             ret\u001b[38;5;241m.\u001b[39mappend(\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret:\n\u001b[1;32m   1201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpchanged()\n",
            "File \u001b[0;32m~/anaconda3/envs/my_projects/lib/python3.9/site-packages/matplotlib/axes/_base.py:74\u001b[0m, in \u001b[0;36m_axis_method_wrapper.__set_name__.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/my_projects/lib/python3.9/site-packages/matplotlib/_api/deprecation.py:297\u001b[0m, in \u001b[0;36mrename_parameter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m     warn_deprecated(\n\u001b[1;32m    293\u001b[0m         since, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas been renamed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m since Matplotlib \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msince\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; support \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    295\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor the old name will be dropped %(removal)s.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    296\u001b[0m     kwargs[new] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(old)\n\u001b[0;32m--> 297\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/my_projects/lib/python3.9/site-packages/matplotlib/axis.py:1969\u001b[0m, in \u001b[0;36mAxis.set_ticklabels\u001b[0;34m(self, labels, minor, fontdict, **kwargs)\u001b[0m\n\u001b[1;32m   1965\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(locator, mticker\u001b[38;5;241m.\u001b[39mFixedLocator):\n\u001b[1;32m   1966\u001b[0m     \u001b[38;5;66;03m# Passing [] as a list of labels is often used as a way to\u001b[39;00m\n\u001b[1;32m   1967\u001b[0m     \u001b[38;5;66;03m# remove all tick labels, so only error for > 0 labels\u001b[39;00m\n\u001b[1;32m   1968\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(locator\u001b[38;5;241m.\u001b[39mlocs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(labels) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(labels) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1969\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1970\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe number of FixedLocator locations\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1971\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(locator\u001b[38;5;241m.\u001b[39mlocs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m), usually from a call to\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1972\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m set_ticks, does not match\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1973\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m the number of labels (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(labels)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1974\u001b[0m     tickd \u001b[38;5;241m=\u001b[39m {loc: lab \u001b[38;5;28;01mfor\u001b[39;00m loc, lab \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(locator\u001b[38;5;241m.\u001b[39mlocs, labels)}\n\u001b[1;32m   1975\u001b[0m     func \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_with_dict, tickd)\n",
            "\u001b[0;31mValueError\u001b[0m: The number of FixedLocator locations (1), usually from a call to set_ticks, does not match the number of labels (2)."
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Fazer previsões no conjunto de teste\n",
        "y_pred = (modelRNN.predict(X_test) > 0.5).astype(\"int32\")  # Converte previsões para 0 ou 1\n",
        "\n",
        "# Gerar a matriz de confusão\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Exibir a matriz de confusão\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Negative\", \"Positive\"])\n",
        "disp.plot()\n",
        "plt.title(\"Matriz de Confusão\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "b794cd41",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0], dtype=int32)"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.unique(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "143714b7",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3018,)"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db761996",
      "metadata": {
        "id": "db761996"
      },
      "source": [
        "### 3.6 Construindo o Modelo com LSTM e Treinando\n",
        "\n",
        "Criar uma arquitetura LSTM para análise de sentimentos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "155465ee",
      "metadata": {
        "id": "155465ee",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 53ms/step - accuracy: 0.9958 - loss: 0.0858 - val_accuracy: 1.0000 - val_loss: 9.3179e-06\n",
            "Epoch 2/10\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 1.8456e-05 - val_accuracy: 1.0000 - val_loss: 4.9449e-06\n",
            "Epoch 3/10\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 1.1365e-05 - val_accuracy: 1.0000 - val_loss: 3.1867e-06\n",
            "Epoch 4/10\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 7.7693e-06 - val_accuracy: 1.0000 - val_loss: 2.2737e-06\n",
            "Epoch 5/10\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 5.7984e-06 - val_accuracy: 1.0000 - val_loss: 1.7262e-06\n",
            "Epoch 6/10\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 4.8365e-06 - val_accuracy: 1.0000 - val_loss: 1.3430e-06\n",
            "Epoch 7/10\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 3.6088e-06 - val_accuracy: 1.0000 - val_loss: 1.0714e-06\n",
            "Epoch 8/10\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 3.0558e-06 - val_accuracy: 1.0000 - val_loss: 8.7668e-07\n",
            "Epoch 9/10\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 2.5057e-06 - val_accuracy: 1.0000 - val_loss: 7.2888e-07\n",
            "Epoch 10/10\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 2.2494e-06 - val_accuracy: 1.0000 - val_loss: 6.1041e-07\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7fa2c8de2fd0>"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# Criar o modelo\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=5000, output_dim=64),\n",
        "    LSTM(128, return_sequences=False),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# Compilar o modelo\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Treinar o modelo\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d26b723b",
      "metadata": {
        "id": "d26b723b"
      },
      "source": [
        "### 3.6 Avaliando o modelo e realizando testes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "d980e563",
      "metadata": {
        "id": "d980e563",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 6.1031e-07\n",
            "Loss: 0.0000, Accuracy: 1.0000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step\n",
            "Review: movie fantastic loved | Sentiment: Negative\n",
            "Review: hated film terrible | Sentiment: Negative\n"
          ]
        }
      ],
      "source": [
        "# Avaliar no conjunto de teste\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Testar o modelo em novas avaliações\n",
        "new_reviews = [\"The movie was fantastic! I loved it.\", \"I hated the film. It was terrible.\"]\n",
        "new_reviews = [preprocess_text(review) for review in new_reviews]\n",
        "new_sequences = tokenizer.texts_to_sequences(new_reviews)\n",
        "new_X = pad_sequences(new_sequences, maxlen=max_len, padding=\"post\")\n",
        "\n",
        "# Fazer previsões\n",
        "predictions = model.predict(new_X)\n",
        "for review, pred in zip(new_reviews, predictions):\n",
        "    sentiment = \"Positive\" if pred > 0.5 else \"Negative\"\n",
        "    print(f\"Review: {review} | Sentiment: {sentiment}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "2cd07554",
      "metadata": {
        "id": "2cd07554"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/hericson/anaconda3/envs/my_projects/lib/python3.9/site-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "The number of FixedLocator locations (1), usually from a call to set_ticks, does not match the number of labels (2).",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[55], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Exibir a matriz de confusão\u001b[39;00m\n\u001b[1;32m      8\u001b[0m disp \u001b[38;5;241m=\u001b[39m ConfusionMatrixDisplay(confusion_matrix\u001b[38;5;241m=\u001b[39mcm, display_labels\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNegative\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPositive\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m----> 9\u001b[0m \u001b[43mdisp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBlues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatriz de Confusão\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
            "File \u001b[0;32m~/anaconda3/envs/my_projects/lib/python3.9/site-packages/sklearn/metrics/_plot/confusion_matrix.py:185\u001b[0m, in \u001b[0;36mConfusionMatrixDisplay.plot\u001b[0;34m(self, include_values, cmap, xticks_rotation, values_format, ax, colorbar, im_kw, text_kw)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m colorbar:\n\u001b[1;32m    184\u001b[0m     fig\u001b[38;5;241m.\u001b[39mcolorbar(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mim_, ax\u001b[38;5;241m=\u001b[39max)\n\u001b[0;32m--> 185\u001b[0m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxticks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_classes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43myticks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_classes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxticklabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisplay_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43myticklabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisplay_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mylabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTrue label\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPredicted label\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_ylim((n_classes \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m))\n\u001b[1;32m    195\u001b[0m plt\u001b[38;5;241m.\u001b[39msetp(ax\u001b[38;5;241m.\u001b[39mget_xticklabels(), rotation\u001b[38;5;241m=\u001b[39mxticks_rotation)\n",
            "File \u001b[0;32m~/anaconda3/envs/my_projects/lib/python3.9/site-packages/matplotlib/artist.py:147\u001b[0m, in \u001b[0;36mArtist.__init_subclass__.<locals>.<lambda>\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mset, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_autogenerated_signature\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;66;03m# Don't overwrite cls.set if the subclass or one of its parents\u001b[39;00m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;66;03m# has defined a set method set itself.\u001b[39;00m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;66;03m# If there was no explicit definition, cls.set is inherited from\u001b[39;00m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;66;03m# the hierarchy of auto-generated set methods, which hold the\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;66;03m# flag _autogenerated_signature.\u001b[39;00m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 147\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[43mArtist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mset\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mset\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "File \u001b[0;32m~/anaconda3/envs/my_projects/lib/python3.9/site-packages/matplotlib/artist.py:1231\u001b[0m, in \u001b[0;36mArtist.set\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1228\u001b[0m     \u001b[38;5;66;03m# docstring and signature are auto-generated via\u001b[39;00m\n\u001b[1;32m   1229\u001b[0m     \u001b[38;5;66;03m# Artist._update_set_signature_and_docstring() at the end of the\u001b[39;00m\n\u001b[1;32m   1230\u001b[0m     \u001b[38;5;66;03m# module.\u001b[39;00m\n\u001b[0;32m-> 1231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcbook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/my_projects/lib/python3.9/site-packages/matplotlib/artist.py:1223\u001b[0m, in \u001b[0;36mArtist._internal_update\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_internal_update\u001b[39m(\u001b[38;5;28mself\u001b[39m, kwargs):\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1218\u001b[0m \u001b[38;5;124;03m    Update artist properties without prenormalizing them, but generating\u001b[39;00m\n\u001b[1;32m   1219\u001b[0m \u001b[38;5;124;03m    errors as if calling `set`.\u001b[39;00m\n\u001b[1;32m   1220\u001b[0m \n\u001b[1;32m   1221\u001b[0m \u001b[38;5;124;03m    The lack of prenormalization is to maintain backcompatibility.\u001b[39;00m\n\u001b[1;32m   1222\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_props\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{cls.__name__}\u001b[39;49;00m\u001b[38;5;124;43m.set() got an unexpected keyword argument \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{prop_name!r}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/my_projects/lib/python3.9/site-packages/matplotlib/artist.py:1199\u001b[0m, in \u001b[0;36mArtist._update_props\u001b[0;34m(self, props, errfmt)\u001b[0m\n\u001b[1;32m   1196\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(func):\n\u001b[1;32m   1197\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1198\u001b[0m                     errfmt\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m), prop_name\u001b[38;5;241m=\u001b[39mk))\n\u001b[0;32m-> 1199\u001b[0m             ret\u001b[38;5;241m.\u001b[39mappend(\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret:\n\u001b[1;32m   1201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpchanged()\n",
            "File \u001b[0;32m~/anaconda3/envs/my_projects/lib/python3.9/site-packages/matplotlib/axes/_base.py:74\u001b[0m, in \u001b[0;36m_axis_method_wrapper.__set_name__.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/my_projects/lib/python3.9/site-packages/matplotlib/_api/deprecation.py:297\u001b[0m, in \u001b[0;36mrename_parameter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m     warn_deprecated(\n\u001b[1;32m    293\u001b[0m         since, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas been renamed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m since Matplotlib \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msince\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; support \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    295\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor the old name will be dropped %(removal)s.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    296\u001b[0m     kwargs[new] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(old)\n\u001b[0;32m--> 297\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/my_projects/lib/python3.9/site-packages/matplotlib/axis.py:1969\u001b[0m, in \u001b[0;36mAxis.set_ticklabels\u001b[0;34m(self, labels, minor, fontdict, **kwargs)\u001b[0m\n\u001b[1;32m   1965\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(locator, mticker\u001b[38;5;241m.\u001b[39mFixedLocator):\n\u001b[1;32m   1966\u001b[0m     \u001b[38;5;66;03m# Passing [] as a list of labels is often used as a way to\u001b[39;00m\n\u001b[1;32m   1967\u001b[0m     \u001b[38;5;66;03m# remove all tick labels, so only error for > 0 labels\u001b[39;00m\n\u001b[1;32m   1968\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(locator\u001b[38;5;241m.\u001b[39mlocs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(labels) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(labels) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1969\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1970\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe number of FixedLocator locations\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1971\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(locator\u001b[38;5;241m.\u001b[39mlocs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m), usually from a call to\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1972\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m set_ticks, does not match\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1973\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m the number of labels (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(labels)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1974\u001b[0m     tickd \u001b[38;5;241m=\u001b[39m {loc: lab \u001b[38;5;28;01mfor\u001b[39;00m loc, lab \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(locator\u001b[38;5;241m.\u001b[39mlocs, labels)}\n\u001b[1;32m   1975\u001b[0m     func \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_with_dict, tickd)\n",
            "\u001b[0;31mValueError\u001b[0m: The number of FixedLocator locations (1), usually from a call to set_ticks, does not match the number of labels (2)."
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Fazer previsões no conjunto de teste\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")  # Converte previsões para 0 ou 1\n",
        "\n",
        "# Gerar a matriz de confusão\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Exibir a matriz de confusão\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Negative\", \"Positive\"])\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title(\"Matriz de Confusão\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "id": "d5cb1821",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[1]], dtype=int32)"
            ]
          },
          "execution_count": 176,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_reviews = [\"An incredible film, I loved the ending\"]\n",
        "new_reviews = [preprocess_text(review) for review in new_reviews]\n",
        "new_sequences = tokenizer.texts_to_sequences(new_reviews)\n",
        "new_X = pad_sequences(new_sequences, maxlen=max_len, padding=\"post\")\n",
        "new_X\n",
        "\n",
        "y_pred = (model.predict(new_X) > 0.5).astype(\"int32\")  # Converte previsões para 0 ou 1\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "id": "8cf37b7c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[0.9274978]], dtype=float32)"
            ]
          },
          "execution_count": 177,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict(new_X)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "179bcf88",
      "metadata": {
        "id": "179bcf88"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2fb97e5",
      "metadata": {
        "id": "b2fb97e5"
      },
      "source": [
        "## Por que LSTM tende a ser melhor do que RNN simples no problema de análise de sentimentos com o dataset IMDB?\n",
        "\n",
        "## 1. Problemas das RNNs Simples\n",
        "As **RNNs simples** sofrem com algumas limitações fundamentais:\n",
        "\n",
        "### 1.1 Gradiente Desaparecendo ou Explodindo\n",
        "- RNNs usam a propagação do gradiente para ajustar os pesos em cada iteração.\n",
        "- Em sequências longas, os gradientes podem se tornar muito pequenos (**desaparecer**) ou muito grandes (**explodir**), o que dificulta o aprendizado eficiente.\n",
        "- Isso faz com que RNNs tenham dificuldades em capturar dependências de longo prazo entre palavras.\n",
        "\n",
        "### 1.2 Memória de Curto Prazo\n",
        "- As RNNs simples têm dificuldade para lembrar informações de etapas muito anteriores na sequência.\n",
        "- Por exemplo, em uma frase longa, uma RNN simples pode esquecer informações importantes do início da frase que influenciam o sentimento geral.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Vantagens do LSTM\n",
        "Os LSTMs foram projetados para resolver os problemas mencionados acima, e isso os torna mais eficazes em tarefas como análise de sentimentos, especialmente com o dataset IMDB, que possui textos longos e complexos.\n",
        "\n",
        "### 2.1 Estrutura Interna do LSTM\n",
        "O LSTM introduz três tipos de **portas** que controlam o fluxo de informações:\n",
        "\n",
        "1. **Porta de Esquecimento**: Decide quais informações devem ser descartadas da memória.\n",
        "2. **Porta de Entrada**: Determina quais novas informações devem ser armazenadas na memória.\n",
        "3. **Porta de Saída**: Decide quais informações da memória serão usadas para calcular a saída.\n",
        "\n",
        "Essas portas permitem que o LSTM:\n",
        "- Retenha informações importantes por longos períodos.\n",
        "- Esqueça informações irrelevantes de forma controlada.\n",
        "\n",
        "### 2.2 Captura de Dependências de Longo Prazo\n",
        "- O LSTM consegue aprender dependências de palavras que estão distantes na sequência.\n",
        "- Por exemplo, na frase:\n",
        "  > \"Embora o início tenha sido lento, o filme foi incrível e emocionante no final.\"\n",
        "  - O sentimento positivo (\"incrível e emocionante\") depende da parte final da frase, mas uma RNN simples pode esquecer o início e fazer uma classificação incorreta.\n",
        "\n",
        "### 2.3 Robustez para Textos Longos\n",
        "- O dataset IMDB contém resenhas de filmes que podem ser bastante longas.\n",
        "- O LSTM consegue processar essas sequências maiores sem perder a conexão semântica entre as palavras.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Resultados Práticos no Dataset IMDB\n",
        "\n",
        "### 3.1 Precisão Maior\n",
        "Estudos mostram que modelos baseados em LSTM frequentemente superam RNNs simples no dataset IMDB, com diferenças significativas de precisão. Isso ocorre porque os LSTMs:\n",
        "- Classificam corretamente textos longos com nuances complexas de sentimentos.\n",
        "- Fazem uso eficiente de informações distribuídas ao longo da sequência.\n",
        "\n",
        "### 3.2 Menor Overfitting\n",
        "- Com técnicas como **Dropout**, os LSTMs conseguem generalizar melhor em conjuntos de teste.\n",
        "- As RNNs simples tendem a memorizar padrões locais e sofrem mais com overfitting.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Quando Usar LSTM ao Invés de RNN\n",
        "Use LSTM nos seguintes casos:\n",
        "- Sequências longas (ex.: análises de sentimentos, traduções automáticas, séries temporais).\n",
        "- Dependências de longo prazo entre elementos da sequência.\n",
        "- Tarefas onde a ordem e o contexto das palavras são cruciais para o entendimento.\n",
        "\n",
        "RNNs simples podem ser suficientes para:\n",
        "- Sequências curtas com padrões locais simples.\n",
        "- Cenários onde o custo computacional é uma preocupação.\n",
        "\n",
        "---\n",
        "\n",
        "## Resumo\n",
        "- O LSTM resolve problemas de curto prazo e gradientes desaparecendo em RNNs simples.\n",
        "- Sua estrutura de portas é especialmente útil para capturar dependências de longo prazo em textos, como os do dataset IMDB.\n",
        "- Em problemas de análise de sentimentos com textos longos e complexos, os LSTMs são mais robustos, eficazes e produzem melhores resultados do que RNNs simples.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e38b06b2",
      "metadata": {
        "id": "e38b06b2"
      },
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "my_projects",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
